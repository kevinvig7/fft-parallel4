\documentclass[10pt,times,mathptm,psfig,final,journal,comsoc]{IEEEtran}                                                             
\IEEEoverridecommandlockouts   
\usepackage	[latin1, utf8]{inputenc}                                                                                        
\usepackage {cite}
\usepackage {amsmath,amssymb,amsfonts}
\usepackage {algorithmic}
\usepackage {graphicx}
\usepackage	{textcomp}
\usepackage	{xcolor}
\usepackage	{threeparttable}
\usepackage	{multirow}
\usepackage {float}
\usepackage	[font=small]{caption}
\usepackage	{mathtools}

	
		
%%%%%%%%
% INICIO
%%%%%%%%
\begin{document}
\title{
\huge \bf VLSI Implementation of a Pipelined 128 points 4-Parallel radix-$\mathbf{2^3}$ FFT Architecture via Folding Transformation\\
}
\author{
\begin{minipage}{0.4\linewidth}
	\raggedleft
	James J. W. Kunst\\
	Kevin H. Viglianco\\
	Daniel R. Garcia
\end{minipage}
\begin{minipage}{0.4\linewidth}
	\raggedright	
	{\tt\small jjwk89@gmail.com}\\
	{\tt\small kevinviglianco@gmail.com}\\	
	{\tt\small dani6rg@gmail.com}			
\end{minipage}			
\\		
[0.5cm]
{\large \bf Digital Signal Processing in Very Large Scale Integration Systems}\\
[0.5cm]
Autumn 2019\\
[0.5cm]
Dr. Keshab K. Parhi	\\
Dr. Ariel L. Pola	\\
[0.5cm]
Universidad Nacional de Córdoba - FCEFyN\\
Av.Vélez Sársfield 1611, X5016GCA, C\'ordoba, Argentina\\
[0.5cm]
Fundación FULGOR\\
Ernesto Romagosa 518, Colinas V. Sarsfield, X5016GQN, Córdoba, Argentina%\\[0.5cm]        
}
\maketitle



%%%%%%%%%%
% Abstract
%%%%%%%%%%
\begin{abstract} 
This work describes the design and the VLSI implementation of a 4-parallel pipelined architecture for the complex fast Fourier transform (CFFT) based on the radix-$\bf 2^3$ algorithm with 128 points using folding transformation and register minimization techniques. In addition, different synthesis reports from the Hardware Description Language (HDL) using different optimization techniques were studied in order to obtain good performance on speed and area with a clock frequency of 500$MHz$ using an open-source FreePDK45 of 45 nm CMOS technology.
\end{abstract}



%%%%%%%%%
% Sección
%%%%%%%%%
\section{Introduccion}
\IEEEPARstart{T}{he} Fast Fourier Transform (FFT) is widely used in different applications fields, particularly in algorithms that involves applying digital signal processing, e.g., calculate the Discrete Fourier Transform (DFT) efficiently. Nowadays is common to use parallel-pipelined architecture in FFT algorithms for real time applications, this allows to achieve good performance with high throughput rates.

There are two main types of pipelined FFT architectures  \cite{shousheng_he_designing_1998}. On one hand, feedback architectures (FB) which can be divided into Single-path Delay Feedback (SDF) and Multi-path Delay Feedback (MDF), both methods transfer data samples between stages serially and use feedback loops. On the other hand, feedforward architectures such as Multi-Path Delay Commutator (MDC) transfers more than one sample per clock cycle and do not use feedback loops.

This work focuses on the design of 4-parallel pipelined architecture \textit{radix}-$2^3$ 128-points for Complex FFT-DIF (Decimation In Frequency). Section \ref{sec:equa}, describes the equations that correspond to Butterfly structure of \textit{radix}-$2^3$ FFT-DIF. In Section \ref{sec:16points}, the design of a 2-parallel pipelined architecture, \textit{radix}-$2^3$ 16-points FFT via folding transformation is presented. In Section \ref{sec:imp128}, the previous design is translate to a 4-parallel, 128-points \textit{radix}-$2^3$ DIF complex FFT, and a float-point simulator in \textit{Matlab} is elaborated, to later be compared with a fixed-point model in order to obtain the best Signal to Quantization Noise Ratio (SQNR).
In Section \ref{sec:results}, different power, area and timing reports with different optimizations such as varying pipelining levels, and the application of canonical signed digit (CSD) are compared to obtain the best performance with a clock frequency of $500MHz$. Finally in Section \ref{sec:conclusions}, some conclusions and discussions are presented.  

\begin{figure} 
	\centering
	\includegraphics[width=1\linewidth]{Diagramas/types_FFT.png}
	\caption{Types of pipelined FFT archicectures for 16 points \cite{type_FFT_MIT}.}
	\label{fig:types_fft}
\end{figure}



%%%%%%%%%
% Sección
%%%%%%%%%
\section{Radix-$2^3$ FFT algorithm} \label{sec:equa}
The \textit{N}-point DFT of an input sequence $x[n]$ is defined as:

\begin{equation}
	X[k] = \sum_{n=0}^{N-1} x[n] \dot W_N^{nk}, \quad k=0,1,...,N-1
\end{equation}
where $W_N^{nk} = e^{-j\frac{2\pi}{N} nk}$. 

Direct computation of the DFT is basically inefficient, primarily because it does not exploit the symmetry and periodicity properties of the phase factor $W_N$, these two properties are:
\begin{align}
	&\text{Symmetry property: } W_N^{k+N/2} = -W_N^k	\\
	&\text{Periodicity property: } W_N^{k+N} = W_N^k
\end{align}

The FFT design based on Cooley-Tukey algorithm is most commonly used to compute the DFT efficiently, this allows to reduce the number of operations from \textit{O($N^2$)} to \textit{O($Nlog_2N$)}. 
The development of computationally efficient algorithms for DFT is possible if a \textit{Divide and Conquer} approach is adopted. This approach is based on the decomposition of an \textit{N} point DFT into successively smaller DFTs, this means that the DFT is calculated as a series of $s=log_\rho N$ stages, where $\rho$ is the base of the \textit{radix}, e.g., in this work this factor is two, so the number of stages for 128 points is 7.

According to \cite{proakis_digital_nodate,oppenheim_tratamiento_2011}, There are two methods to design FFT algorithms: 
\paragraph{Decimation in time (DIT)}
In this method the \textit{N}-point data sequence $x[n]$ is split into two $N/2$-point data sequences, thus, is possible to obtain two different functions by decimating $x[n]$ by a factor of 2. The decimation of the data sequence can be repeated again, until the resulting sequences are reduced to one-point sequence. 
\paragraph{Decimation in frequency (DIF)}
This method is based on the divide-and-conquer technique, where the DFT formula is split into two summations, one of which involves the sum over the first $N/2$ data points and the second sum involves the last $N/2$ data points.


In each decomposition, the basic computing unit that processes the samples is called \textit{butterfly}. In general, each butterfly involves one complex multiplication and two complex additions. The main difference between DIT and DIF is the instant in which the multiplication by $W_N^\phi$ is computed, the input samples can be multiplied before or after the butterfly structure, as is depicted in Fig.\ref{fig:difdit}.

\begin{figure} [ht!]
	\centering
	\includegraphics[width=0.65\linewidth]{Diagramas/miSeccionFiguras/DifDit.pdf}
	\caption{Basic butterflies computation in the decimation in time and frequency.}
	\label{fig:difdit}
\end{figure}

Another difference between the two methods is that the input samples in DIF algorithms are organized in natural order but the output are not in order, in which case a reordering circuit at the output is needed, in contrast with the DIT algorithms where the input sequence are not in order but the output is in natural order.

According to the methodology presented in \cite{proakis_digital_nodate}, it is possible to apply the mathematical expressions of \textit{radix-}$2^3$ DIF as is explain in \cite{jia_efficient_nodate}. These fundamental equations are describe in equation (\ref{eqn:radix}):

%%Ecuaciones RADIX
\begingroup
\allowdisplaybreaks
\begin{small}
\input{tex/radix_eq.tex}
\end{small}
\endgroup


Fig. \ref{fig:8ponits_df} and Fig. \ref{fig:8ponits_dfg} show the equivalent diagram of interconnections and data flows from the equations presented in (\ref{eqn:radix}).

%The use of higher value radices lead to different amount of rotators. If we compare the quantity of rotators of an architecture \textit{radix-}$2$ FFT with an architecture \textit{radix-}$2^k$ FFT, this last has less number of phase factors.

\begin{figure}[ht] 
	\centering
	\includegraphics[width=\linewidth]{Diagramas/miSeccionFiguras/8PuntosRadix8Conexion.pdf}
	\caption{Structure of interconnection for \textit{radix-}$2^3$ DIF DFT.}
	\label{fig:8ponits_df}
\end{figure}

\begin{figure} [ht]
	\centering
	\includegraphics[width=\linewidth]{Diagramas/miSeccionFiguras/8PuntosRadix8Burbujas.pdf}
	\caption{Data flow graph (DFG) based in equations (\ref{eqn:radix}).}
	\label{fig:8ponits_dfg}
\end{figure}

\subsection{16 points DFT}
The next step is to find the suitable rotator factors for the 16 point DFT, the equations in (\ref{eqn:radix}) are essential for this design and they were evaluated to get $C_{8k+i} = \sum_{n=0}^{16/8-1} \{ \cdot \}, $ for $k=0,1$. The structure for the 16 point DFT is described in Fig. \ref{fig:16points_df} and Fig. \ref{fig:16points_dfg}. 

\begin{figure} [ht]
	\centering
	\includegraphics[width=\linewidth]{Diagramas/miSeccionFiguras/16PuntosRadix8Conexion.pdf}
	\caption{Flow graph of a \textit{radix-}$2^3$ 16-point DIF DFT}
	\label{fig:16points_df}
\end{figure}

\begin{figure} [ht]
	\centering
	\includegraphics[width=\linewidth]{Diagramas/miSeccionFiguras/16PuntosRadix8Burbujas.pdf}
	\caption{Data flow graph (DFG) for a \textit{radix-}$2^3$ 16-point DIF DFT}
	\label{fig:16points_dfg}
\end{figure}

\subsection{128 points DFT}
With these first approaches is possible the application of the divide and conquer strategy by decomposing the 128-point DFT and calculating each coefficient $C_{8k+i} = \sum_{n=0}^{128/8-1} \{ \cdot \}, $ for $k=0,1,...,(128/8)-1$, this way a  chain sequence of butterflies is obtained together with its corresponding rotation factor and the correct index of the samples in which they must be added or multiplied. Using this technique is possible to do a subdivision of butterflies stages, as is shown in Fig. \ref{fig:128_block_descomp}, the decomposition of the 128 point DFT involves three stages of butterflies resulting in a set of eight 16 point DFTs. Finally, Fig. \ref{fig:128points_conn} shows the complete architecture for the  \textit{radix-}$2^3$ 128-point DIF DFT with a total of seven stages where each stage  contains 64 butterflies of radix-2 base.

\begin{figure} [ht]
	\centering
	\includegraphics[width=0.85\linewidth]{Diagramas/miSeccionFiguras/BloquesDft.pdf}
	\caption{Decomposing a \textit{radix-}$2^3$ 128-point DFT.}
	\label{fig:128_block_descomp}
\end{figure}

%
%With the DFT's previous decomposition is possible to get whole the coefficients $C_{8k+i}$ that represent the samples in frequency $X[k]$ obtained from a combination of the different instances of $x[n]$. This method take us to apply step by step the equation (\ref{eqn:radix}) to our design and finally arrive to the definitive architecture, the Fig. \ref{fig:128ponits_conn} shows us a \textit{radix-}$2^3$ 128-point DIF DFT with a total of seven stages where each stage is building with 64 butterflies of radix-2 base.

\begin{figure} 
	\centering
	\includegraphics[width=\linewidth]{Diagramas/miSeccionFiguras/128PuntosRadix8Conexion.pdf}
	\caption{Flow graph of a \textit{radix-}$2^3$ 128-point DIF DFT}
	\label{fig:128points_conn}
\end{figure}



%%%%%%%%%%
%% Sección
%%%%%%%%%%
\section{Design of a FFT architecture via folding transformation} \label{sec:16points}
In this section, the architecture proposed in \cite{ayinala_pipelined_2012} together with the folding transformation and register minimization techique described in \cite{folding_parhi_book} is used to obtain a 16-point DIF FFT 4-parallel architecture, then, the same method is extended  to achieve a 128-point DIF FFT 4-parallel architecture.



%%%%%%%%%%%%%
%% Subsección
%%%%%%%%%%%%%
\subsection{4-Parallel radix-$2^3$ 16-Points}
The flow graph of a 16-point DIF FFT radix-$2^3$ with main base radix-2 is shown in Fig. \ref{fig:16points_df}. The graph is divided into four stages, each of them consist of a set of butterflies and multipliers. The twiddle factor between the stages indicates a multiplication by $W^k_N$, where $W_N$ denotes the \textit{N}th root of unity, with its exponent evaluated modulo N. This can be represented as a DFG as shown in Fig. \ref{fig:16points_dfg}, where the nodes represents the butterfly computations of the radix-2 FFT algorithm. 

The folding transformation is used on the DFG to derive a pipelined architecture, to do this a folding set is needed. A folding set is an ordered set of operations executed by the same functional unit, each folding set contains K entries, where K is called the folding factor. The operation in the \textit{j}th position within the folding set (where goes from $0$ to $K-1$) is executed by the functional unit during the time partition, this term is called the folding order.
In order to derive the folding equations a node graph is needed, where an edge $e$ is consider to connect the nodes \textit{U} and \textit{V} with $w(e)$ delays. Let the executions of the \textit{l}th iteration of the nodes \textit{U} and \textit{V} be scheduled at the time units $Kl+u$ and $Kl+v$ respectively, where $u$ and $v$ are the folding orders of the nodes \textit{U} and \textit{V}, respectively. The folding equation for the edge $e$ is:
\begin{equation}\label{eqn:fold_equation}
D_F(U \to V) = Kw(e)-P_U+v-u
\end{equation}

where $P_U$ is the number of pipeline stages in the hardware unit which executes the node U.

Considering the folding of the DFG in Fig. \ref{fig:16points_dfg} with the folding sets:
\begin{align*}%\label{eq:foldingset_16}
A&= \{ A0,A2,A4,A6 \}  & A'&= \{ A1,A3,A5,A7 \} \\
B&=\{ B1,B3,B0,B2 \}   &B'&=\{ B5,B7,B4,B6 \} 	\\
C&=\{ C2,C1,C3,C0 \}   &C'&=\{ C6,C5,C7,C4 \} 	\\ 
D&=\{ D3,D0,D2,D1 \}   &D'&=\{ D7,D4,D6,D5 \}  
\end{align*}

Assuming that the butterfly operations do not have any pipeline stages ($P_A=P_B=P_C=P_D=0$), the folding equations can be derived for all edges,
thus, the expression \textit{without retiming} can be obtained from (\ref{eqn:fold_equation}).

%%% Ecuaciones de folding sin pipe
\begin{small}
\input{tex/eq_folding.tex}
\end{small}
For the folded system to be realizable, $D_F(U\to V)\geq0$ must hold for all the edges in the DFG. Retimming and/or pipeline can be applied to satisfy this property, if the DFG in Fig. \ref{fig:16points_dfg} is pipelined/retimmed as shown in Fig. \ref{fig:dfg_16_ret} the system is realizable and the folded delays for the edges are given by the equations that represent a folding set \textit{with retiming}.

\begin{figure} 
\centering
\includegraphics[width=\linewidth]{Diagramas/16points_dfg_ret.png}
\caption{Data Flow graph (DFG) of a radix-2 16-point DIF FFT with retiming and pipeline.}
\label{fig:dfg_16_ret}
\end{figure}
%%%ecuaciones de folding con pipe
\begin{small}
\input{tex/eq_folding_pipe.tex}
\end{small}

The number of registers required to implement the folding equations in (\ref{eqn:ConRetiming}) is 80, in order to minimize the number of registers  the register minimization technique is needed. To apply this technique lets consider
the output of node $A0$ to be $y_{(0)}$ and $y_{(8)}$, and the output of the node A1 to be $y_{(1)}$ and $y_{(9)}$, applying this method successively with the rest of the nodes A a linear life time chart for this stage is obtain as is shown in Fig.\ref{fig:tab-life-a}. Applying this criteria to the rest of the stages the life time chart for nodes B and C are obtained as is shown in Fig.\ref{fig:tab-life-b} and Fig.\ref{fig:tab-life-c}  respectively. The resulting maximum number of registers for each stage are 8, 4 and 8 respectively, therefore the total number of registers is reduced from 80 to 20. More information about this method can be found on \cite{folding_parhi_book}.

\begin{figure}[t!]
\centering
 \includegraphics[width=\linewidth]{Diagramas/life_chart_a.png}
\caption{Linear lifetime chart for the variables $y_{(0)}, y_{(1)},...,y_{(15)}$ for a 16-point FFT architecture.}
\label{fig:tab-life-a}
\end{figure}
\begin{figure}[t!]
\centering
 \includegraphics[width=\linewidth]{Diagramas/life_chart_b.png}
\caption{Linear lifetime chart for the variables $z_{(0)}, z_{(1)},...,z_{(15)}$ for a 16-point FFT architecture.}
\label{fig:tab-life-b}
\end{figure}
\begin{figure}[t!]
\centering
 \includegraphics[width=\linewidth]{Diagramas/life_chart_c.png}
\caption{Linear lifetime chart for the variables $w_{(0)}, w_{(1)},...,w_{(15)}$ for a 16-point FFT architecture.}
\label{fig:tab-life-c}
\end{figure}

The register allocation tables for the lifetime charts are shown in Fig. \ref{fig:tab-aloc-a}, \ref{fig:tab-aloc-b} and \ref{fig:tab-aloc-c} for stage A, B and C respectively. Fig.\ref{fig:folding16_stage1} and  Fig.\ref{fig:folding16_stage2} show the designations of registers for the stage A and B respectively used in the allocation tables, the designation for stage C are similar to stage A. The folded architecture in Fig.\ref{fig:folding_16_arch} is synthesized using the folding equations and the register allocation tables. The dataflow for each stage can be seen in Tab. \ref{tab:folding16_mux}, the control signal for stage A and B can be implemented by dividing the clock signal to 4 and 2 respectively, for stage C the control signal is the same that the stage A. 
Note that in Fig. \ref{fig:folding_16_arch} the inputs and output are not ordered, to order these variables an extra logic is needed, this imply using more registers and multiplexers.

The inputs for each folding node are represented in a matrix where the values in the same column is the data that flows in parallel, and values in the same row correspond to the data that flows through the same path in consecutive clock cycles. The first two rows represent the inputs of the superior BF and the others two represents the input of the inferior BF. The same criteria is used for represent the rotators constants, where each number $k$ of the matrix represent a multiplication by $W^k_N$.

\begin{figure} 
\centering
 \includegraphics[width=0.9\linewidth]{Diagramas/tab_life_a.eps}
\caption{Register allocation table for the data represented in \ref{fig:tab-life-a}}
\label{fig:tab-aloc-a}
\end{figure}
\begin{figure} 
\centering
 \includegraphics[width=0.63\linewidth]{Diagramas/tab_life_b.eps}
\caption{Register allocation table for the data represented in \ref{fig:tab-life-b}}
\label{fig:tab-aloc-b}
\end{figure}
\begin{figure} 
\centering
 \includegraphics[width=0.95\linewidth]{Diagramas/tab_life_c.eps}
\caption{Register allocation table for the data represented in \ref{fig:tab-life-c}}
\label{fig:tab-aloc-c}
\end{figure}

%Tabla MUX foldin 16
\input{tex/folding16_mux.tex}
    \begin{figure} 
        \centering
        \includegraphics[width=0.8\linewidth]{Diagramas/folding_stage1.png}
        \caption{Registers names used in Fig. \ref{fig:tab-aloc-a} for stage 1.}
        \label{fig:folding16_stage1}
    \end{figure}

    \begin{figure} 
        \centering
        \includegraphics[width= 0.8\linewidth]{Diagramas/folding_stage2.png}
        \caption{Registers names used in Fig. \ref{fig:tab-aloc-b} for stage 2.}
        \label{fig:folding16_stage2}
    \end{figure}
        

The different types of rotators used in Fig. \ref{fig:folding_16_arch} are shown in Fig. \ref{fig:rotators}, the description of each are:
\begin{itemize}
	\item Trivial rotator: They can be carried out by interchanging the real and imaginary components and/or changing the sign of the data.
	\item Constant CSD rotator: They can be carried out by interchanging the real and imaginary components and a multiplication by a unique constant fractional number, in this case we will use a CSD multiplier to reduce the area utilized.
	\item General rotator: They can be carried out by interchanging the real and imaginary components and/or a multiplication by more than one constant fractional numbers, in this case we will use a general multiplier.
\end{itemize}

\begin{figure} 
	\centering
	\includegraphics[width=0.6\linewidth]{Diagramas/miSeccionFiguras/Rotadores.pdf}
	\caption{Symbols used for the different types of rotators}
	\label{fig:rotators}
\end{figure}

\begin{figure*} 
	\centering
	\includegraphics[width=0.85\linewidth]{Diagramas/folding-16.pdf}%folding-16.png: Eliminé el último cuadro de índices d ela salida.
	\caption{Folding architecture for the computation of a radix-$2^3$ 16-point DIF complex FFT.}
	\label{fig:folding_16_arch}
\end{figure*}



%%%%%%%%%%%%%
%% Subsección
%%%%%%%%%%%%%
\section{4-Parallel radix-$2^3$ 128-Points}   \label{sec:imp128}
The previously described method can be used in the design of a 4-Parallel radix-$2^3$ 128-Points architecture. 
The pipelined/retimmed  DFG for this design is shown in Fig. \ref{fig:pipe_dfg_128}, the folding sets are listed in Table \ref{tab:fold_set_128}, and in Fig.\ref{fig:folding_128}  the folded architecture is shown.

%% Tabla de folding
\begin{small}
\input{tex/folding128.tex}
\end{small}

\begin{figure} 
	\centering
	\includegraphics[width=\linewidth]{Diagramas/miSeccionFiguras/128puntosRadix8BurbujasPipelined_Kevin.pdf}
	\caption{Pipelined/retimmed DFG of a radix-$2^3$ 128-point DIF complex FFT.}
	\label{fig:pipe_dfg_128}
\end{figure}



%%%%%%%%%%
%% Sección
%%%%%%%%%%
\subsection{Implementation of a 128-point FFT}
In this section the implementation of the 4-parallel architecture for the computation of 128-point \textit{radix}-$2^3$ DIF complex FFT is described.

%\cite{garrido_pipelined_2013,garrido_feedforward_2018}

In order to compare and validate the operation of the design presented in this work a \textit{MATLAB} simulator has been elaborated to later write  a Synthesizable \textit{Verilog} code with different levels of optimizations using a powerful tool like \textit{Synopsys} to get a final design in $@45nm$ Standard Cells \cite{freePdk}.



%%%%%%%%%%%%%
%% Subseccion
%%%%%%%%%%%%%
\subsection{Floating and Fixed point Simulator description}

\begin{figure}%[ht!] 
	\centering
	\includegraphics[width=0.92\linewidth]{Diagramas/DftInputSignal.pdf}
	\caption{Input signal $x[n]$ in time domain}
	\label{fig:dftinputsignal}
\end{figure}

\begin{figure}[ht!] 
	\centering
	\includegraphics[width=0.95\linewidth]{Diagramas/DftFixedPoint.pdf}
	\caption{Output samples, absolute value vs frequency $|X[k]|$}
	\label{fig:dftfixedpoint}
\end{figure}

The input signal to the design is shown in Fig. \ref{fig:dftinputsignal}, the signal  will be a mixture of two sinusoid signals with different frequency and normalized amplitude as is describe in equations \ref{eq:inputSignal1} and \ref{eq:inputSignal2}, where $f_1=100Hz$, $f_2=1000Hz$ and $T_s$ is the sampled period.
\begin{align}
x'[n] &= cos(2\pi f_1 n T_s) + cos(2\pi f_2 n T_s)\label{eq:inputSignal1}  \\
x[n] &= x'[n]/max\{x'[n]\} \label{eq:inputSignal2}						
\end{align}


In each stage of the Fig. \ref{fig:4paralelo128pradix8cuantizacion1}, input samples that propagate  through the stages will be carefully quantized with the purpose of getting a high SQNR (Signal to Quantization Noise Ratio).

\begin{equation}\label{eq:sqnr}
  \begin{multlined}
SQNR_{dB} =\\
10log_{10} \bigg(  \frac{  Var\{Signal_{FloatPoint}\}  }{  Var\{Signal_{FloatPoint} - Signal_{FixedPoint}\}}  \bigg)
 \end{multlined}
\end{equation}


SQNR computation represents the logarithmic relationship between float signal variance over error variance from an given signal.

The input signal $x[n]$ is quantized with a value of $S(10,9)$, this representation means a signed (S) number with $10$ total bits and $9$ fractional bits. The value calculated of SQNR for the input is $56.9dB$. Following the same steps, we can compute the SQNR for the \textit{twiddle} factors and the design output.

Twiddles factor are quantized with a relation of $S(11,9)$ and the complex output signal $X[k]$ with $S(22,15)$, output quantization for the real part is $46.8dB$ and for the imaginary part $47.3dB$. In general, a value of quantization close to $50dB$ is a good approximation.


The \textit{MATLAB} fixed-point model is shown in Fig. \ref{fig:4paralelo128pradix8cuantizacion1} and  Fig.\ref{fig:dftfixedpoint} shows the output signal in the frequency domain.

\begin{figure}[ht!] 
	\centering
	\includegraphics[width=0.3\linewidth]{Diagramas/miSeccionFiguras/Shift.pdf}
	\caption{Circuit for data shuffling}
	\label{fig:shift}
\end{figure}
\begin{figure}[ht!] 
	\centering
	\includegraphics[width=0.6\linewidth]{Diagramas/miSeccionFiguras/ButterComplejo.pdf}
	\caption{Complex butterfly }
	\label{fig:buttercomplejo}
\end{figure}
\begin{figure}[ht!] 
	\centering
	\includegraphics[width=0.65\linewidth]{Diagramas/miSeccionFiguras/SumMult.pdf}
	\caption{Complex multiplier and complex adder}
	\label{fig:summult}
\end{figure}

The equivalent circuit of the combination of latencies (delays registers) and switches placed between the stages in Fig. \ref{fig:4paralelo128pradix8cuantizacion1} are represented in Fig. \ref{fig:shift}. This circuits are used to appropriately order samples in each butterflies input.

The combination of latencies (delays registers) and switches placed between the stages in Fig. \ref{fig:4paralelo128pradix8cuantizacion1} are used to appropriately order samples in each butterflies input and its equivalent circuit is represented in Fig. \ref{fig:shift}.

The different elements such as multipliers and butterflies process complex numbers as is shown in Fig. \ref{fig:buttercomplejo} and \ref{fig:summult}, this means that
is essential to divide the signal in its real and imaginary part with the purpose of process them independently.

A \textit{general rotator} (full complex multiplier) computes two multiplications and one addition for the real and imaginary part, as is describe in \ref{fig:summult}, but in case of a \textit{trivial rotator} (multiplication by  \textit{i}), there are no multiplications of additions, it only swap the numbers and change the sign if is necessary, as is shown in Fig .These relations allows to achieve a good design optimization and are important at the moment of calculating the quantization process to ensure an appropriate quantity of bits.



%%%%%%%%%%%%%
%% Subsección
%%%%%%%%%%%%%
\section{Verilog (HDL) Model ,optimizations and results}  \label{sec:results}
%\begin{figure*} 
%	\centering
%	\includegraphics[width=\linewidth]{Diagramas/V5_esquema_p.eps}
%	\caption{RTL (Register transfer level) design for a 4-parallel \textit{radix}-$2^3$ 128-point DIF FFT with Optimization}
%	\label{fig:v5esquemap}
%\end{figure*}

In this section the different design instances to model the DFT in hardware will be described. With the purpose to have a global view of the optimization levels to achieve the requested \textit{data arrival time} of $1/500Mhz=2ns$ and the lowest power consumption, four design have been implemented. The design instances were synthesized by Synopsys tool in order to build an interconnection of Standard Cells and generate a complete set of \textit{timing-area-power report} showed in Table \ref{tab:reporte2}, \ref{tab:reporte4}, \ref{tab:reporte5} and  \ref{tab:reporte6}.


The first design was made from the base design showed in Fig.\ref{fig:folding_128}, this hardware model has butterflies modules that work in combination with multipliers and each multiplier has associated a memory block that contains the twiddle factors. In this first approach all multipliers are \textit{full}, each stage has a control module that enables the inversion of the switching block, this control signal is also sent to the multipliers in order to work synchronously with the switching. To avoid the bit growth generated by the addition and multiplication, a quantization block is necessary, the quantizer consist of  saturation and truncate operations. The synthesis report is summarize in Table \ref{tab:reporte2}, notice that a total power consumption is $695.564 mW$ and the data arrival time is greater than minimum period established of $2ns$ resulting in a time violation.
In order to minimize the \textit{critical path} and consumption a second design with \textit{pipelined} registers after the quantization blocks was implemented, and also the \textit{trivial} multipliers (multiplication by $-1j$) were implemented in stages one, two and four, this significantly reduced the size of the binary word resulting in a reduction in the total power as is shown in Table \ref{tab:reporte4}, however the time violation was still detected in this design.
In the third case of optimization an internal pipelined to each butterfly block was added in order to reduce the critical path even more, as the results shown in Table \ref{tab:reporte5}, this design achieves the data required time.
Finally, in the fourth level of optimization showed in Fig.\ref{fig:4paralelo128pradix8cuantizacion1}, the full multipliers from stage two and five were modified to work with \textit{CSD}, achieving a total power consumption of $646.924 mW$. 

%\ref{fig:v5esquemap}
%efficiently with constant coefficients, these new multipliers are  because the twiddle factors in these stages are always $-je^{-j\frac{\pi}{4}}$ and $e^{-j\frac{\pi}{4}}$.



%%%%%%%%%%
%% Seccion
%%%%%%%%%%
%%%%%%%%%%%%%%%%% Aqui quede 29/9/2020 19:27 

%\section{Results}  \label{sec:results}
%
%
%, with this first approach we decide make a set of optimizations to folding architecture as a pipelined cutset between stages of DFT. In this way as we can see in Table \ref{tab:reporte5}, we reduced power, area and timing. 
%
%In contrast with the first instance of design, we found in the last case of implementation a slack of time equal to zero, that means the clock period satisfy the time constraint at 500MHz.

%% primera version sin pipe y sin saturation, no llega a 500MHz
\input{tex/reporte2.tex}
%\input{tex/reporte3.tex}
\input{tex/reporte4.tex}
%% Segunda version con pipe y saturation, llega a 500MHz y consume menos con menos area
\input{tex/reporte5.tex}
%% Tercera version con pipe, saturacion y CSD 
\input{tex/reporte6.tex}	



%%%%%%%%%%
%% Sección
%%%%%%%%%%
%\FloatBarrier
\section{Conclusions} \label{sec:conclusions}
This work has presented a VLSI Implementation of a Pipelined 128 points 4-Parallel radix-$2^3$ FFT architecture via folding transformation.
 %% Calcular reduccion de registros
The folding transformation applied reduced significantly (equal to the folded factor, i.e. 64 times) the number of functional units, and therefore the silicon area at the expense of increasing the computation time by the same factor.
%, therefore is necessary to add pipeline cutsets and in order to achieve the required sample period.
Folding technique resulted in an architecture that uses a large number of registers, however by applying a register minimization technique the number of register were significantly reduced from .... to 188 resulting in a final design with less area and power consumption. As for the fixed point implementation, a high SQNR of 46.8dB and 47.3dB for the real and the imaginary part respectably was able to achieve by using saturation and truncation blocks. 
Lastly a series of optimization were necessary to accomplish the required working frequency. The DFT implementation without any optimization level got to work at 166MHz. Applying a series of pipelines cutsets in the quantization and butterflies blocks the final architecture is implementable at the required clock frequency (500 MHz) at the cost of incrementing the numbers of sequential cells. Finally, by using CSD multipliers a significantly reduction in combinational cells was possible resulting in a even more reduction in the total power consumption. 
The  implementations evolution is summarize in a bar chart in Fig. \ref{fig:atp}, where the last implementation (Imp 4) achieves the require critical path to address the requested \textit{data arrival time} (Slack equals to 0 ns), and also the lowest area and power consumption is obtain.
As a final commentary, is worth to notice that in order to use this implementation in a real time application a reordering circuit at the input and the output of the system needs to be include, this circuit present an additional area and power consumption to be considered in the final design. 


% The Fourier Transform without folding technique processes 128 entry points of samples which are ordered but its output are disordered and it is necessary a reordering circuit. 
%Fourier Transform with folding technique needs a reordering circuit at the input. 


%nombrar tabla


%The design implemented a quantizer block which works with saturation and truncated, the round method was not used because we reached a high SQNR.

%The folding transformation applied reduced significantly (equal to the folded factor, i.e. 64 times) the number of functional units, and therefore the silicon area at the expense of increasing the computation time by the same factor, therefore is necessary to add pipeline cutsets and a careful quantization in order to achieve the required sample period with an acceptable SNR.
%The number of DFT points is related with the radix-base, we can write as \textit{radix}-$8$, this representation can be expressed as \textit{radix}-$2^3$ that means we can decompose in smaller radixes with main base-2, an advantage of using a hight radix is reduced the number of multipliers at expense of increase the routing.

\begin{figure*} 
	\centering
	\includegraphics[width=0.6\linewidth]{Diagramas/folding-128.png}
	\caption{Folding architecture for the computation of a radix-$2^3$ 128-point DIF complex FFT.}
	\label{fig:folding_128}
\end{figure*}

\begin{figure*} 
	\centering
	\includegraphics[width=0.8\linewidth]{Diagramas/folding-128-quant-pipe.png}
	\caption{Quantization for a 128-point 4-parallel complex FFT architecture}
	\label{fig:4paralelo128pradix8cuantizacion1}
\end{figure*}

\begin{figure*}[ht!]
	\centering
	\includegraphics[width=0.85\linewidth]{Diagramas/areaTiempoPower.pdf}
	\caption{Timing-Area-Power evolution.}
	\label{fig:atp}
\end{figure*}



%\pagebreak
%%%%%%%%%%%%%%
% Bibliografia
%%%%%%%%%%%%%%
\newpage
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,referenciasFFT}
%%%%%%%%
% FIN
%%%%%%%%
\end{document}
